{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Materials and Methods writeup, the data covers **17** campaigns for the bank. The campaigns occurred between May 2008 and November 2010, corresponding to a total of 79354 contacts, with a 8% success rate.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MISSING VALUES ANALYSIS ===\n",
      "1. Standard missing values (NaN/null):\n",
      "No standard missing values found in any column.\n",
      "2. 'Unknown' values in categorical features:\n",
      "   job: 330 (0.80%)\n",
      "   marital: 80 (0.19%)\n",
      "   education: 1731 (4.20%)\n",
      "   default: 8597 (20.87%)\n",
      "   housing: 990 (2.40%)\n",
      "   loan: 990 (2.40%)\n",
      "=== DATA TYPE ANALYSIS ===\n",
      "\n",
      "Current data types:\n",
      "   age: int64\n",
      "   job: object\n",
      "   marital: object\n",
      "   education: object\n",
      "   default: object\n",
      "   housing: object\n",
      "   loan: object\n",
      "   contact: object\n",
      "   month: object\n",
      "   day_of_week: object\n",
      "   duration: int64\n",
      "   campaign: int64\n",
      "   pdays: int64\n",
      "   previous: int64\n",
      "   poutcome: object\n",
      "   emp.var.rate: float64\n",
      "   cons.price.idx: float64\n",
      "   cons.conf.idx: float64\n",
      "   euribor3m: float64\n",
      "   nr.employed: float64\n",
      "   y: object\n",
      "\n",
      "=== DATA TYPE RECOMMENDATIONS ===\n",
      "\n",
      "1. Categorical features that should remain as object/string type:\n",
      "   job: Currently object - OK\n",
      "   marital: Currently object - OK\n",
      "   education: Currently object - OK\n",
      "   default: Currently object - OK\n",
      "   housing: Currently object - OK\n",
      "   loan: Currently object - OK\n",
      "   contact: Currently object - OK\n",
      "   month: Currently object - OK\n",
      "   day_of_week: Currently object - OK\n",
      "   poutcome: Currently object - OK\n",
      "   y: Currently object - OK\n",
      "2. Numeric features:\n",
      "   age: Currently int64 - OK\n",
      "   duration: Currently int64 - OK\n",
      "   campaign: Currently int64 - OK\n",
      "   pdays: Currently int64 - OK\n",
      "   previous: Currently int64 - OK\n",
      "   emp.var.rate: Currently float64 - OK\n",
      "   cons.price.idx: Currently float64 - OK\n",
      "   cons.conf.idx: Currently float64 - OK\n",
      "   euribor3m: Currently float64 - OK\n",
      "   nr.employed: Currently float64 - OK\n",
      "3. Other:\n",
      "   - 'pdays': Value of 999 indicates 'not previously contacted' - maybe needs transformed to something more reasonable?\n",
      "   - 'duration': drop?\n",
      "   - Target variable 'y': Binary categorical ('yes'/'no') - will need encoding\n"
     ]
    }
   ],
   "source": [
    "# 1. Check for missing values (including 'unknown' values in categorical features)\n",
    "print(\"=== MISSING VALUES ANALYSIS ===\")\n",
    "\n",
    "# Standard missing values (.isnull())\n",
    "print(\"1. Standard missing values (NaN/null):\")\n",
    "missing_counts = df.isnull().sum()\n",
    "if missing_counts.sum() == 0:\n",
    "    print(\"No standard missing values found in any column.\")\n",
    "else:\n",
    "    print(missing_counts[missing_counts > 0])\n",
    "\n",
    "# Check for 'unknown' values in categorical columns\n",
    "print(\"2. 'Unknown' values in categorical features:\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "unknown_counts = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    unknown_count = (df[col] == 'unknown').sum()\n",
    "    if unknown_count > 0:\n",
    "        unknown_counts[col] = unknown_count\n",
    "        unknown_pct = (unknown_count / len(df)) * 100\n",
    "        print(f\"   {col}: {unknown_count} ({unknown_pct:.2f}%)\")\n",
    "\n",
    "if not unknown_counts:\n",
    "    print(\"   No 'unknown' values found in categorical columns\")\n",
    "\n",
    "# 2. Examine current data types\n",
    "print(\"=== DATA TYPE ANALYSIS ===\\n\")\n",
    "print(\"Current data types:\")\n",
    "for col in df.columns:\n",
    "    print(f\"   {col}: {df[col].dtype}\")\n",
    "\n",
    "# 3. Identify features that need type conversion\n",
    "print(\"\\n=== DATA TYPE RECOMMENDATIONS ===\\n\")\n",
    "\n",
    "# Check if categorical features are properly typed\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', \n",
    "                       'contact', 'month', 'day_of_week', 'poutcome', 'y']\n",
    "print(\"1. Categorical features that should remain as object/string type:\")\n",
    "for feat in categorical_features:\n",
    "    if feat in df.columns:\n",
    "        print(f\"   {feat}: Currently {df[feat].dtype} - OK\")\n",
    "\n",
    "# Check numeric features\n",
    "numeric_features = ['age', 'duration', 'campaign', 'pdays', 'previous', \n",
    "                   'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', \n",
    "                   'euribor3m', 'nr.employed']\n",
    "print(\"2. Numeric features:\")\n",
    "for feat in numeric_features:\n",
    "    if feat in df.columns:\n",
    "        print(f\"   {feat}: Currently {df[feat].dtype} - OK\")\n",
    "\n",
    "# Other\n",
    "print(\"3. Other:\")\n",
    "print(\"   - 'pdays': Value of 999 indicates 'not previously contacted' - maybe needs transformed to something more reasonable?\")\n",
    "print(\"   - 'duration': drop?\")\n",
    "print(\"   - Target variable 'y': Binary categorical ('yes'/'no') - will need encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (41188, 21)\n",
      "Cleaned dataset shape: (30488, 21)\n",
      "Rows removed: 10700 (25.98%)\n",
      "\n",
      "Columns that had 'unknown' values:\n",
      "  job: 330 rows\n",
      "  marital: 80 rows\n",
      "  education: 1731 rows\n",
      "  default: 8597 rows\n",
      "  housing: 990 rows\n",
      "  loan: 990 rows\n",
      "\n",
      "Dropping 'euribor3m' column...\n",
      "Final dataset shape: (30488, 20)\n"
     ]
    }
   ],
   "source": [
    "# Cleanup - Drop all rows with 'unknown' values\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "\n",
    "# Drop rows where any column contains 'unknown'\n",
    "df_cleaned = df[~df.isin(['unknown']).any(axis=1)]\n",
    "\n",
    "print(f\"Cleaned dataset shape: {df_cleaned.shape}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_cleaned)} ({((len(df) - len(df_cleaned))/len(df)*100):.2f}%)\")\n",
    "\n",
    "# Show which columns had 'unknown' values\n",
    "print(\"\\nColumns that had 'unknown' values:\")\n",
    "for col in df.columns:\n",
    "    unknown_count = (df[col] == 'unknown').sum()\n",
    "    if unknown_count > 0:\n",
    "        print(f\"  {col}: {unknown_count} rows\")\n",
    "\n",
    "# Update df to use the cleaned version\n",
    "df = df_cleaned\n",
    "\n",
    "# Drop euribor3m column\n",
    "print(f\"\\nDropping 'euribor3m' column...\")\n",
    "df = df.drop('euribor3m', axis=1)\n",
    "print(f\"Final dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 30488 entries, 0 to 41187\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             30488 non-null  int64  \n",
      " 1   job             30488 non-null  object \n",
      " 2   marital         30488 non-null  object \n",
      " 3   education       30488 non-null  object \n",
      " 4   default         30488 non-null  object \n",
      " 5   housing         30488 non-null  object \n",
      " 6   loan            30488 non-null  object \n",
      " 7   contact         30488 non-null  object \n",
      " 8   month           30488 non-null  object \n",
      " 9   day_of_week     30488 non-null  object \n",
      " 10  duration        30488 non-null  int64  \n",
      " 11  campaign        30488 non-null  int64  \n",
      " 12  pdays           30488 non-null  int64  \n",
      " 13  previous        30488 non-null  int64  \n",
      " 14  poutcome        30488 non-null  object \n",
      " 15  emp.var.rate    30488 non-null  float64\n",
      " 16  cons.price.idx  30488 non-null  float64\n",
      " 17  cons.conf.idx   30488 non-null  float64\n",
      " 18  nr.employed     30488 non-null  float64\n",
      " 19  y               30488 non-null  object \n",
      "dtypes: float64(4), int64(5), object(11)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "The business objective is to predict whether a client will subscribe to a term deposit based on data from marketing campaigns. By accurately identifying clients who are more likely to subscribe, the bank can focus their telemarketing efforts on high-potential customers, reducing wasted calls and improving conversion rates. This predictive model would help the marketing team allocate resources more efficiently and increase the overall ROI of their campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns: ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan']\n",
      "   age        job  marital            education default housing loan\n",
      "0   56  housemaid  married             basic.4y      no      no   no\n",
      "2   37   services  married          high.school      no     yes   no\n",
      "3   40     admin.  married             basic.6y      no      no   no\n",
      "4   56   services  married          high.school      no      no  yes\n",
      "6   59     admin.  married  professional.course      no      no   no\n"
     ]
    }
   ],
   "source": [
    "# Bank features and category encoding\n",
    "\n",
    "# Select only bank client features\n",
    "# According to the problem description, bank client features are:\n",
    "# age, job, marital, education, default, housing, loan\n",
    "\n",
    "bank_features = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan']\n",
    "X_bank = df[bank_features].copy()\n",
    "y = df['y'].copy()\n",
    "\n",
    "print(f\"Feature columns: {bank_features}\")\n",
    "print(X_bank.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded feature matrix shape: (30488, 28)\n",
      "Target variable distribution: {0: 26629, 1: 3859}\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "\n",
    "# Task 2 & 3: Encode categorical variables and target variable\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# First encode the target variable 'y' from yes/no to 1/0\n",
    "y_encoded = (y == 'yes').astype(int)\n",
    "\n",
    "# Separate numeric and categorical features\n",
    "numeric_features = ['age']\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan']\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_categorical_encoded = encoder.fit_transform(X_bank[categorical_features])\n",
    "\n",
    "# Get feature names for encoded columns\n",
    "feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Create DataFrame with encoded categorical features\n",
    "X_categorical_df = pd.DataFrame(X_categorical_encoded, columns=feature_names, index=X_bank.index)\n",
    "\n",
    "# Combine numeric and encoded categorical features using pandas concat\n",
    "X_encoded = pd.concat([X_bank[numeric_features], X_categorical_df], axis=1)\n",
    "\n",
    "print(f\"Encoded feature matrix shape: {X_encoded.shape}\")\n",
    "print(f\"Target variable distribution: {y_encoded.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values in encoded features...\n",
      "âœ“ No missing values found in the encoded features\n",
      "\n",
      "Final feature matrix X shape: (30488, 28)\n",
      "Final target vector y shape: (30488,)\n",
      "Number of features: 28\n",
      "Number of samples: 30488\n"
     ]
    }
   ],
   "source": [
    "# Verify no missing values and create final feature matrix\n",
    "\n",
    "print(\"Checking for missing values in encoded features...\")\n",
    "missing_values = X_encoded.isnull().sum()\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"âœ“ No missing values found in the encoded features\")\n",
    "else:\n",
    "    print(\"Missing values found:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "# Create final feature matrix X and target vector y\n",
    "X = X_encoded\n",
    "y = y_encoded\n",
    "\n",
    "print(f\"\\nFinal feature matrix X shape: {X.shape}\")\n",
    "print(f\"Final target vector y shape: {y.shape}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 24390 samples\n",
      "Test set size: 6098 samples\n",
      "\n",
      "Class distribution in training set:\n",
      "y\n",
      "0    0.873432\n",
      "1    0.126568\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution in test set:\n",
      "y\n",
      "0    0.873401\n",
      "1    0.126599\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Train/Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Using 80/20 split with stratification to maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Performance using DummyClassifier:\n",
      "DummyClassifier using the most_frequent strategy found class to be: ('0')\n",
      "Accuracy: 0.8734\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model using DummyClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a dummy classifier that always predicts the most frequent class\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "\n",
    "# Fit the dummy classifier\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "\n",
    "# Calculate baseline accuracy\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_dummy)\n",
    "\n",
    "print(\"Baseline Model Performance using DummyClassifier:\")\n",
    "print(f\"DummyClassifier using the most_frequent strategy found class to be: ('{dummy_clf.classes_[0]}')\")\n",
    "print(f\"Accuracy: {baseline_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Performance:\n",
      "Training time: 0.015 seconds\n",
      "Training accuracy: 0.8734\n",
      "Test accuracy: 0.8734\n",
      "\n",
      "Improvement over baseline: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features for logistic regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train logistic regression model\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = log_reg.predict(X_train_scaled)\n",
    "start_time = time.time()\n",
    "y_pred_test = log_reg.predict(X_test_scaled)\n",
    "test_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Calculate accuracies\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Logistic Regression Model Performance:\")\n",
    "print(f\"Training time: {train_time:.3f} seconds\")\n",
    "print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"\\nImprovement over baseline: {test_accuracy - baseline_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Model Performance:\n",
      "Training time: 0.004 seconds\n",
      "Training accuracy: 0.8780\n",
      "Test accuracy: 0.8622\n",
      "Improvement over baseline: -0.0112\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors (KNN) Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create and train KNN model with default settings (n_neighbors=5)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn_train_time = time.time() - start_time\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_knn = knn.predict(X_train_scaled)\n",
    "start_time = time.time()\n",
    "y_pred_test_knn = knn.predict(X_test_scaled)\n",
    "knn_test_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Calculate accuracies\n",
    "knn_train_accuracy = accuracy_score(y_train, y_pred_train_knn)\n",
    "knn_test_accuracy = accuracy_score(y_test, y_pred_test_knn)\n",
    "\n",
    "print(\"K-Nearest Neighbors Model Performance:\")\n",
    "print(f\"Training time: {knn_train_time:.3f} seconds\")\n",
    "print(f\"Training accuracy: {knn_train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {knn_test_accuracy:.4f}\")\n",
    "print(f\"Improvement over baseline: {knn_test_accuracy - baseline_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Performance:\n",
      "Training time: 0.039 seconds\n",
      "Test time: 0.002 seconds\n",
      "Training accuracy: 0.9005\n",
      "Test accuracy: 0.8526\n",
      "Improvement over baseline: -0.0208\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and train Decision Tree model with default settings\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "dt.fit(X_train, y_train)  # Decision trees don't require scaled features\n",
    "dt_train_time = time.time() - start_time\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_dt = dt.predict(X_train)\n",
    "start_time = time.time()\n",
    "y_pred_test_dt = dt.predict(X_test)\n",
    "dt_test_time = time.time() - start_time\n",
    "\n",
    "# Calculate accuracies\n",
    "dt_train_accuracy = accuracy_score(y_train, y_pred_train_dt)\n",
    "dt_test_accuracy = accuracy_score(y_test, y_pred_test_dt)\n",
    "\n",
    "print(\"Decision Tree Model Performance:\")\n",
    "print(f\"Training time: {dt_train_time:.3f} seconds\")\n",
    "print(f\"Test time: {dt_test_time:.3f} seconds\")\n",
    "print(f\"Training accuracy: {dt_train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {dt_test_accuracy:.4f}\")\n",
    "print(f\"Improvement over baseline: {dt_test_accuracy - baseline_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Model Performance:\n",
      "Training time: 6.455 seconds\n",
      "Training accuracy: 0.8738\n",
      "Test accuracy: 0.8737\n",
      "Improvement over baseline: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine (SVM) Model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create and train SVM model with default settings\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "svm.fit(X_train_scaled, y_train)  # SVM requires scaled features\n",
    "svm_train_time = time.time() - start_time\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_svm = svm.predict(X_train_scaled)\n",
    "y_pred_test_svm = svm.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracies\n",
    "svm_train_accuracy = accuracy_score(y_train, y_pred_train_svm)\n",
    "start_time = time.time()\n",
    "svm_test_accuracy = accuracy_score(y_test, y_pred_test_svm)\n",
    "svm_test_time = time.time() - start_time\n",
    "\n",
    "\n",
    "print(\"Support Vector Machine Model Performance:\")\n",
    "print(f\"Training time: {svm_train_time:.3f} seconds\")\n",
    "print(f\"Training accuracy: {svm_train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {svm_test_accuracy:.4f}\")\n",
    "print(f\"Improvement over baseline: {svm_test_accuracy - baseline_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Time</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.015045</td>\n",
       "      <td>0.873432</td>\n",
       "      <td>0.873401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.878024</td>\n",
       "      <td>0.862250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.039160</td>\n",
       "      <td>0.900492</td>\n",
       "      <td>0.852575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>6.455350</td>\n",
       "      <td>0.873801</td>\n",
       "      <td>0.873729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train Time  Train Accuracy  Test Accuracy\n",
       "0     Logistic Regression    0.015045        0.873432       0.873401\n",
       "1     K-Nearest Neighbors    0.003697        0.878024       0.862250\n",
       "2           Decision Tree    0.039160        0.900492       0.852575\n",
       "3  Support Vector Machine    6.455350        0.873801       0.873729"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Comparison Summary\n",
    "\n",
    "\n",
    "# Create a DataFrame to compare all models (with numeric values)\n",
    "from turtle import mode\n",
    "\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'K-Nearest Neighbors', 'Decision Tree', 'Support Vector Machine'],\n",
    "    'Train Time': [train_time, knn_train_time, dt_train_time, svm_train_time],\n",
    "    'Train Accuracy': [train_accuracy, knn_train_accuracy, dt_train_accuracy, svm_train_accuracy],\n",
    "    'Test Time': [test_time, knn_test_time, dt_test_time, svm_test_time],\n",
    "    'Test Accuracy': [test_accuracy, knn_test_accuracy, dt_test_accuracy, svm_test_accuracy]\n",
    "})\n",
    "#| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "display_df = model_comparison.loc[:, ['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy']].copy()\n",
    "display(display_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Time</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Time</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Ranking_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.8734</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.8734</td>\n",
       "      <td>0.9905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>6.455</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.8737</td>\n",
       "      <td>0.8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.8526</td>\n",
       "      <td>0.3969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.8780</td>\n",
       "      <td>0.1723</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>0.3744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                   Model Train Time Train Accuracy Test Time  \\\n",
       "0     1     Logistic Regression      0.015         0.8734    0.0004   \n",
       "3     2  Support Vector Machine      6.455         0.8738    0.0004   \n",
       "2     3           Decision Tree      0.039         0.9005    0.0018   \n",
       "1     4     K-Nearest Neighbors      0.004         0.8780    0.1723   \n",
       "\n",
       "  Test Accuracy Ranking_Score  \n",
       "0        0.8734        0.9905  \n",
       "3        0.8737        0.8999  \n",
       "2        0.8526        0.3969  \n",
       "1        0.8622        0.3744  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets see if we can get a ranking done just to figure out what we could pick instead of just accuracy\n",
    "# Calculate ranking score based on: accuracy (most important), test time, train time\n",
    "# Normalize test accuracy (0-1 scale, higher is better)\n",
    "\n",
    "max_acc = model_comparison['Test Accuracy'].max()\n",
    "min_acc = model_comparison['Test Accuracy'].min()\n",
    "if max_acc != min_acc:\n",
    "    model_comparison['Accuracy_Score'] = (model_comparison['Test Accuracy'] - min_acc) / (max_acc - min_acc)\n",
    "else:\n",
    "    model_comparison['Accuracy_Score'] = 1.0\n",
    "\n",
    "# Normalize test time (0-1 scale, lower is better so we invert)\n",
    "max_test_time = model_comparison['Test Time'].max()\n",
    "min_test_time = model_comparison['Test Time'].min()\n",
    "if max_test_time != min_test_time:\n",
    "    model_comparison['Test_Time_Score'] = 1 - (model_comparison['Test Time'] - min_test_time) / (max_test_time - min_test_time)\n",
    "else:\n",
    "    model_comparison['Test_Time_Score'] = 1.0\n",
    "\n",
    "# Normalize training time (0-1 scale, lower is better so we invert)\n",
    "max_train_time = model_comparison['Train Time'].max()\n",
    "min_train_time = model_comparison['Train Time'].min()\n",
    "if max_train_time != min_train_time:\n",
    "    model_comparison['Train_Time_Score'] = 1 - (model_comparison['Train Time'] - min_train_time) / (max_train_time - min_train_time)\n",
    "else:\n",
    "    model_comparison['Train_Time_Score'] = 1.0\n",
    "\n",
    "# Calculate weighted ranking score (accuracy > test time > train time)\n",
    "accuracy_weight = 0.6\n",
    "test_time_weight = 0.3\n",
    "train_time_weight = 0.1\n",
    "model_comparison['Ranking_Score'] = (model_comparison['Accuracy_Score'] * accuracy_weight + \n",
    "                                     model_comparison['Test_Time_Score'] * test_time_weight +\n",
    "                                     model_comparison['Train_Time_Score'] * train_time_weight)\n",
    "\n",
    "# Sort by ranking score (descending)\n",
    "model_comparison = model_comparison.sort_values('Ranking_Score', ascending=False)\n",
    "model_comparison['Rank'] = range(1, len(model_comparison) + 1)\n",
    "\n",
    "# Format the DataFrame for better display\n",
    "model_comparison['Train Time'] = model_comparison['Train Time'].apply(lambda x: f\"{x:.3f}\")\n",
    "model_comparison['Train Accuracy'] = model_comparison['Train Accuracy'].apply(lambda x: f\"{x:.4f}\")\n",
    "model_comparison['Test Time'] = model_comparison['Test Time'].apply(lambda x: f\"{x:.4f}\")\n",
    "model_comparison['Test Accuracy'] = model_comparison['Test Accuracy'].apply(lambda x: f\"{x:.4f}\")\n",
    "model_comparison['Ranking_Score'] = model_comparison['Ranking_Score'].apply(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "# Select columns to display\n",
    "display_cols = ['Rank', 'Model', 'Train Time', 'Train Accuracy', 'Test Time', 'Test Accuracy', 'Ranking_Score']\n",
    "display_df = model_comparison[display_cols]\n",
    "\n",
    "# Also display as a formatted table\n",
    "display(display_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
